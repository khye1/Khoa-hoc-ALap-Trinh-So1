import streamlit as st
from openai import OpenAI
import os


# ====================== UTILITIES ======================
def read_file(filename: str) -> str:
    """ƒê·ªçc n·ªôi dung file text (utf-8) m·ªôt c√°ch an to√†n."""
    try:
        with open(filename, "r", encoding="utf-8") as f:
            return f.read().strip()
    except FileNotFoundError:
        st.error(f"Kh√¥ng t√¨m th·∫•y file: {filename}")
        st.stop()


def get_openai_client() -> OpenAI:
    """L·∫•y API key v√† kh·ªüi t·∫°o OpenAI client."""
    api_key = st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")
    if not api_key:
        st.error(
            "üîë Kh√¥ng t√¨m th·∫•y OPENAI_API_KEY.\n\n"
            "Vui l√≤ng th√™m v√†o **Secrets** c·ªßa Streamlit Community Cloud "
            "ho·∫∑c ƒë·∫∑t bi·∫øn m√¥i tr∆∞·ªùng `OPENAI_API_KEY`."
        )
        st.stop()
    return OpenAI(api_key=api_key)


# ====================== CONFIG ======================
# ƒê·ªçc c√°c file c·∫•u h√¨nh m·ªôt l·∫ßn duy nh·∫•t
TITLE           = read_file("00.xinchao.txt")
SYSTEM_PROMPT   = read_file("01.system_trainning.txt")
ASSISTANT_GREET = read_file("02.assistant.txt")
MODEL_NAME      = read_file("gpt-4o-mini").strip()  # ho·∫∑c b·∫°n c√≥ th·ªÉ hard-code n·∫øu mu·ªën

# Kh·ªüi t·∫°o client
client = get_openai_client()

# Sidebar info
st.sidebar.write("üîê ƒê√£ c√≥ API key:", "‚úÖ" if client.api_key else "‚ùå")
st.sidebar.caption(f"Model: `{MODEL_NAME}`")


# ====================== LAYOUT ======================
# Logo + Ti√™u ƒë·ªÅ
col1, col2, col3 = st.columns([3, 2, 3])
with col2:
    try:
        st.image("israel-flag.png", use_container_width=True)
    except:
        pass

st.markdown(
    f'<h1 style="text-align: center; font-size: 28px; margin-bottom: 30px;">{TITLE}</h1>',
    unsafe_allow_html=True,
)

# CSS ƒë·∫πp h∆°n, h·ªó tr·ª£ dark mode nh·∫π v√† avatar
st.markdown("""
<style>
    .chat-message {
        padding: 12px 16px;
        border-radius: 12px;
        margin-bottom: 12px;
        max-width: 80%;
        line-height: 1.5;
    }
    .assistant {
        background-color: #f1f3f5;
        border-left: 4px solid #0a7cff;
    }
    .user {
        background-color: #e3f2fd;
        margin-left: auto;
        border-right: 4px solid #0a7cff;
    }
    .assistant::before { content: "ü§ñ "; font-size: 1.3em; }
    .user::after     { content: "üë§ "; font-size: 1.3em; }
    @media (prefers-color-scheme: dark) {
        .assistant { background-color: #2d3748; }
        .user     { background-color: #1e3a8a; }
    }
</style>
""", unsafe_allow_html=True)


# ====================== SESSION STATE ======================
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system",    "content": SYSTEM_PROMPT},
        {"role": "assistant", "content": ASSISTANT_GREET},
    ]


# ====================== HI·ªÇN TH·ªä L·ªäCH S·ª¨ CHAT ======================
for msg in st.session_state.messages:
    if msg["role"] == "assistant":
        st.markdown(
            f'<div class="chat-message assistant">{msg["content"]}</div>',
            unsafe_allow_html=True,
        )
    elif msg["role"] == "user":
        st.markdown(
            f'<div class="chat-message user">{msg["content"]}</div>',
            unsafe_allow_html=True,
        )


# ====================== INPUT & STREAMING ======================
if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n t·∫°i ƒë√¢y..."):
    # Th√™m tin nh·∫Øn ng∆∞·ªùi d√πng
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.markdown(
        f'<div class="chat-message user">{prompt}</div>',
        unsafe_allow_html=True,
    )

    # Placeholder ƒë·ªÉ stream ph·∫£n h·ªìi
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""

        # G·ªçi API v·ªõi stream=True
        stream = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
            stream=True,
            temperature=0.7,
        )

        # Hi·ªÉn th·ªã t·ª´ng chunk ngay l·∫≠p t·ª©c
        for chunk in stream:
            if chunk.choices[0].delta.content:
                full_response += chunk.choices[0].delta.content
                message_placeholder.markdown(
                    f'<div class="chat-message assistant">{full_response}‚ñå</div>',
                    unsafe_allow_html=True,
                )

        # X√≥a con tr·ªè nh·∫•p nh√°y khi ho√†n th√†nh
        message_placeholder.markdown(
            f'<div class="chat-message assistant">{full_response}</div>',
            unsafe_allow_html=True,
        )

    # L∆∞u ph·∫£n h·ªìi v√†o l·ªãch s·ª≠
    st.session_state.messages.append({"role": "assistant", "content": full_response})

    # T·ª± ƒë·ªông reruns ƒë·ªÉ c·∫≠p nh·∫≠t giao di·ªán
    st.rerun()